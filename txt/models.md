### NER–моделі для MITIE

Завдяки нашому проанотованому корпусу української мови ми мали змогу натренувати модель, що дозволяє автоматичний пошук іменованих сутностей (імен, географічних назв, назв компаній, тощо) у незнайомих текстах. Для пошуку NER сутностей ми обрали [бібліотеку MITIE](https://github.com/mit-nlp/MITIE/). Ця бібліотека є відкритою, її ліцензія дозволяє безкоштовне використання навіть у комерційних проектах. MITIE також забезпечує високу точність завдяки поєднанню звичних features для тексту та CCA embeddings. Хоч MITIE й написана на С++, вона також має інтерфейси для інших мов програмування: C, Python, Java, Matlab.

Для обчислення CCA embeddings ми використовували назбираний корпус українських новин, статей вікіпедії та художньої літератури.

Ми також побудували модель для пошуку іменованих сутностей російською мовою, використовуючи [анотований корпус](https://github.com/dialogue-evaluation/factRuEval-2016) підготовлений організаторами конференції [Dialogue 2016](http://www.dialog-21.ru/evaluation/2016/ner/). Для обчислення CCA embeddings ми використовували корпус статей російської вікіпедії.


## Word embeddings (Word2Vec, GloVe, LexVec)

На базі зібраних нами корпусів новин, статей, художньої літератури, законів та юридичних текстів ми обчислили найпоширеніши word embeddings: [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html) (та його покращену версію [LexVec](https://github.com/alexandres/lexvec/)) й [GloVe](http://www-nlp.stanford.edu/projects/glove/). Ми вирішили опублікувати ці моделі, тому що їх обчислення займає доволі багато часу та серверних ресурсів.

Ми створили окремі моделі для кожної категорії текстів з 300d векторами. Ми також обчислили їх для лематизованих версій тих самих корпусів. Якщо вам потрібні інші налаштування моделей — скористайтеся корпусами, що ми підготували, та обчисліть моделі згідно ваших потреб.
